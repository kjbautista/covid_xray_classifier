{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pn-xPPzz1tHf",
    "outputId": "9fab08f1-16c6-49e1-8952-bef095fbc135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from imutils import build_montages\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "# Set up CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == torch.device(\"cpu\"):\n",
    "  print('Set the runtime to GPU!')\n",
    "else:\n",
    "  print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add label to save files\n",
    "save_lab = '-net3'\n",
    "\n",
    "##### change path to x-ray files location !!!!! ######\n",
    "path = \"/pine/scr/k/a/kathlyne/comp562/final_project/\" \n",
    "######################################################\n",
    "\n",
    "# Select epoch based on training results\n",
    "sel_epoch = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "2tXTXCNWGPkW",
    "outputId": "baf4f469-2b39-4c64-a260-dbd45f7677d7"
   },
   "outputs": [],
   "source": [
    "cols = [\"Filename\",\"BrixiaScoreGlobal\",\"ConsensusTestset\"]\n",
    "cutoff = 8 # optimal cutoff based on literature (add citation)\n",
    "\n",
    "# Get list of file paths to images\n",
    "metadata = pd.read_csv(os.path.join(path,\"metadata.csv\"),sep=\";\",usecols=cols)\n",
    "file_list = metadata.Filename.copy()\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    tmp = str(os.path.splitext(file_list[i])[0])\n",
    "    file_list[i] = os.path.join(path,\"segmented_png\",(tmp+\".png\"))\n",
    "\n",
    "# Define image labels based on cutoff value\n",
    "labels = (metadata.BrixiaScoreGlobal >= cutoff)\n",
    "  # 0 = low Brixia score (< 8)\n",
    "  # 1 = high Brixia score (>= 8)\n",
    "\n",
    "# Split into training/val and test sets\n",
    "trainval_files = file_list[(metadata.ConsensusTestset == 0)]\n",
    "trainval_labels = labels[metadata.ConsensusTestset == 0]\n",
    "test_files = file_list[metadata.ConsensusTestset == 1]\n",
    "test_labels = labels[metadata.ConsensusTestset == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BTO4WSRHjx5B"
   },
   "outputs": [],
   "source": [
    "### Data Pre-processing ###\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), # convert to tensor\n",
    "     transforms.Normalize((0.5,), (0.5,))]) # normalize\n",
    "\n",
    "### Define custom dataset ###\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self,image_paths,image_labels,transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.image_labels = image_labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self,idx):\n",
    "        image_filepath = self.image_paths.iloc[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        label = (self.image_labels.iloc[idx]).astype(int)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "### Create datasets ###\n",
    "trainval_set = XRayDataset(trainval_files,trainval_labels,transform)\n",
    "test_set = XRayDataset(test_files,test_labels,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xUReic7lqU9c"
   },
   "outputs": [],
   "source": [
    "batch_size = 32 # randomly-chosen - ideally, needs a hyperparameter search\n",
    "\n",
    "# Load the datasets using Pytorch DataLoader\n",
    "trainvalloader = torch.utils.data.DataLoader(trainval_set,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "\n",
    "image_size = 512 # pixel dimensions of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dG6-GG2rGc8"
   },
   "source": [
    "**Creating the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4SyUV5WdrDoN"
   },
   "outputs": [],
   "source": [
    "## CNN architecture\n",
    "class simple_cnn(torch.nn.Module):\n",
    "  def __init__(self,input_channels,n_filters,filt_size,input_size,n_classes):\n",
    "    super().__init__()\n",
    "\n",
    "    # inputs\n",
    "    self.input_channels = input_channels # number of channels in the input image\n",
    "    self.n_filters = n_filters # list of number of filters in each layer\n",
    "    self.filt_size = filt_size # list of filter sizes\n",
    "    self.input_size = input_size  # size of the input image\n",
    "    self.n_classes = n_classes;\n",
    "\n",
    "    # avg pooling\n",
    "    self.pool = torch.nn.AvgPool2d(2,2) \n",
    "\n",
    "    # conv layers\n",
    "    self.conv0 = torch.nn.Conv2d(in_channels = input_channels, out_channels = n_filters[0], kernel_size = filt_size[0], padding = 0, stride = 2)\n",
    "    self.conv1 = torch.nn.Conv2d(in_channels = n_filters[0], out_channels = n_filters[1], kernel_size = filt_size[1], padding = 0, stride = 2)\n",
    "    self.conv2 = torch.nn.Conv2d(in_channels = n_filters[1],out_channels = n_filters[2], kernel_size = filt_size[2], padding = 0, stride = 2)\n",
    "    \n",
    "    # linear layer - applies a linear transformation\n",
    "    self.fc0 = torch.nn.Linear(in_features = 288, out_features = 64)\n",
    "    self.fc1 = torch.nn.Linear(in_features = 64, out_features = 2) \n",
    "    \n",
    "    # batch normalization\n",
    "    self.batchnorm1 = torch.nn.BatchNorm2d(n_filters[0])\n",
    "    self.batchnorm2 = torch.nn.BatchNorm2d(n_filters[1])\n",
    "    self.batchnorm3 = torch.nn.BatchNorm2d(n_filters[2])\n",
    "\n",
    "    # dropout\n",
    "    self.drop2d1 = torch.nn.Dropout2d(0.2)\n",
    "    self.drop2d2 = torch.nn.Dropout2d(0.3)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.conv0(x)\n",
    "    x = self.batchnorm1(x)\n",
    "    x = self.drop2d1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.pool(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.batchnorm2(x)\n",
    "    x = self.drop2d2(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.pool(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.batchnorm3(x)\n",
    "    x = self.drop2d2(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.pool(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc0(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.fc1(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Who6aijGraew",
    "outputId": "8b100697-f636-47cf-e59c-a57b5e3639d4"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "input_channels = 1 # grayscale image\n",
    "n_filters = [8,16,32] \n",
    "filt_size = [16,16,16]\n",
    "input_size = image_size\n",
    "n_classes = 2\n",
    "model = simple_cnn(input_channels,n_filters,filt_size,input_size,n_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fs9wNuINN6fD",
    "outputId": "966ef2e5-2afe-4d54-8cc4-7ce79ea198aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load model at selected epoch defined above\n",
    "model.load_state_dict(torch.load(path+'/covid_xray_classifier'+save_lab+'epoch'+str(sel_epoch)+'.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train on combined test and validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cost function ###\n",
    "# Cross Entropy Loss\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "### Optimizer ###\n",
    "# AdamW Optimizer (with L2 regularization)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "for idx,data in enumerate(trainvalloader):\n",
    "    ### Get data, send it to the GPU\n",
    "    img,lab = data\n",
    "    img = img.to(device)\n",
    "    lab = lab.to(device)\n",
    "\n",
    "    ### Model calculations\n",
    "    # zero the gradients out\n",
    "    optimizer.zero_grad()\n",
    "    # get the predictions of the model and compute the loss\n",
    "    out = model(img)\n",
    "    # print(out.shape,lab.shape)\n",
    "    loss = loss_fn(out,lab)\n",
    "    # calculate the gradient and take a step with the model\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the final model\n",
    "PATH = path+'/covid_xray_classifier'+save_lab+'-final.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBzWKAlMN_eH"
   },
   "source": [
    "**Running the model on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8kO8KSdYOdDI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 150 test images: 76%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "lab_pred = []\n",
    "lab_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # iterate over test data\n",
    "    for data in testloader:\n",
    "        img, lab = data\n",
    "        img = img.to(device)\n",
    "        lab = lab.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        out = model(img)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        pred = torch.argmax(out.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (pred == lab).sum().item()\n",
    "\n",
    "        lab_pred.extend(pred.tolist()) # Save predictions\n",
    "        lab_true.extend(lab.tolist()) # Save true labels\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct // total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upvg0CudUT8K"
   },
   "source": [
    "**Generate Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Qf6BqJxmS3Nq",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classes\n",
    "classes = ('Low Brixia Score','High Brixia Score')\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(lab_true, lab_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix), index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (7,5))\n",
    "sn.heatmap(df_cm, annot=True,fmt='2.0%')\n",
    "plt.savefig(path+'/confusion_matrix'+save_lab+'.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp562",
   "language": "python",
   "name": "comp562"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
